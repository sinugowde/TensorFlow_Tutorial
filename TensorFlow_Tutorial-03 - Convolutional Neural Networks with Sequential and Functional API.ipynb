{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow_Tutorial-03 - Convolutional Neural Networks with Sequential and Functional API",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOfvpVfV8okAWIIMtuHI7jI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HFzVooPgdR1L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10"
      ],
      "metadata": {
        "id": "DEjrhtXHidUb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference\n",
        "# http://karpathy.github.io/2011/04/27/manually-classifying-cifar10/"
      ],
      "metadata": {
        "id": "pLP5QIhgk8OT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# convert the data types to float 32 bit & then normalize between 0~1\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmLmvQYJi8kd",
        "outputId": "ca8542a0-1da7-486b-8efd-9e2a3776796d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement with Sequential API"
      ],
      "metadata": {
        "id": "GrVqdUvHmflQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "     keras.Input(shape=(32, 32, 3)),\n",
        "     layers.Conv2D(32, 3, padding='valid', activation='relu'),\n",
        "     layers.MaxPool2D(pool_size=(2,2)),\n",
        "     layers.Conv2D(64, 3, activation='relu'),\n",
        "     layers.MaxPool2D(),\n",
        "     layers.Conv2D(128, 3, activation='relu'),\n",
        "     layers.Flatten(),\n",
        "     layers.Dense(64, activation='relu'),\n",
        "     layers.Dense(10)\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chTUjjVYmWvA",
        "outputId": "6ef0fa0d-d442-4917-cfc2-eee3e3d34e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                131136    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 225,034\n",
            "Trainable params: 225,034\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=3e-4),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_MCDA7Toevf",
        "outputId": "6334b0c8-f37b-41c5-fc1b-4f3a1bede28b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 - 65s - loss: 1.6626 - accuracy: 0.3941 - 65s/epoch - 83ms/step\n",
            "Epoch 2/10\n",
            "782/782 - 70s - loss: 1.3485 - accuracy: 0.5158 - 70s/epoch - 90ms/step\n",
            "Epoch 3/10\n",
            "782/782 - 63s - loss: 1.2246 - accuracy: 0.5684 - 63s/epoch - 81ms/step\n",
            "Epoch 4/10\n",
            "782/782 - 63s - loss: 1.1226 - accuracy: 0.6064 - 63s/epoch - 81ms/step\n",
            "Epoch 5/10\n",
            "782/782 - 63s - loss: 1.0377 - accuracy: 0.6361 - 63s/epoch - 80ms/step\n",
            "Epoch 6/10\n",
            "782/782 - 64s - loss: 0.9755 - accuracy: 0.6598 - 64s/epoch - 81ms/step\n",
            "Epoch 7/10\n",
            "782/782 - 63s - loss: 0.9234 - accuracy: 0.6791 - 63s/epoch - 81ms/step\n",
            "Epoch 8/10\n",
            "782/782 - 63s - loss: 0.8757 - accuracy: 0.6968 - 63s/epoch - 80ms/step\n",
            "Epoch 9/10\n",
            "782/782 - 63s - loss: 0.8305 - accuracy: 0.7124 - 63s/epoch - 81ms/step\n",
            "Epoch 10/10\n",
            "782/782 - 63s - loss: 0.7919 - accuracy: 0.7274 - 63s/epoch - 81ms/step\n",
            "157/157 - 4s - loss: 0.9110 - accuracy: 0.6929 - 4s/epoch - 23ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9110416769981384, 0.6929000020027161]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the above model has just 3 convolution layers plus 10 epochs & with this, we see around 73% of training accuracy & around 70% accuracy on validation.\n",
        "# So this accuracy can be increased:\n",
        "# - increase the number of epochs\n",
        "# - increase the number of convolution layers"
      ],
      "metadata": {
        "id": "kb5fIEg4vNt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement with Functional API"
      ],
      "metadata": {
        "id": "jM-0dZw4w673"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lets do it with function\n",
        "def functional_model():\n",
        "  inputs = keras.Input(shape=(32, 32, 3))\n",
        "  x = layers.Conv2D(32, 3)(inputs)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = layers.MaxPool2D()(x)\n",
        "  x = layers.Conv2D(64, 5, padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = layers.Conv2D(128, 3)(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(64, activation='relu')(x)\n",
        "  outputs = layers.Dense(10)(x)\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "Y8ge7ILIxElD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = functional_model()\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=3e-4),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGugEO9M34wY",
        "outputId": "49053cc4-da5e-4d30-e87a-d910fcb0c706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 - 254s - loss: 1.3255 - accuracy: 0.5254 - 254s/epoch - 325ms/step\n",
            "Epoch 2/10\n",
            "782/782 - 254s - loss: 0.9069 - accuracy: 0.6816 - 254s/epoch - 325ms/step\n",
            "Epoch 3/10\n",
            "782/782 - 258s - loss: 0.7493 - accuracy: 0.7366 - 258s/epoch - 330ms/step\n",
            "Epoch 4/10\n",
            "782/782 - 251s - loss: 0.6430 - accuracy: 0.7749 - 251s/epoch - 321ms/step\n",
            "Epoch 5/10\n",
            "782/782 - 252s - loss: 0.5542 - accuracy: 0.8081 - 252s/epoch - 322ms/step\n",
            "Epoch 6/10\n",
            "782/782 - 252s - loss: 0.4740 - accuracy: 0.8360 - 252s/epoch - 322ms/step\n",
            "Epoch 7/10\n",
            "782/782 - 254s - loss: 0.4096 - accuracy: 0.8586 - 254s/epoch - 325ms/step\n",
            "Epoch 8/10\n",
            "782/782 - 259s - loss: 0.3472 - accuracy: 0.8814 - 259s/epoch - 331ms/step\n",
            "Epoch 9/10\n",
            "782/782 - 261s - loss: 0.2877 - accuracy: 0.9052 - 261s/epoch - 334ms/step\n",
            "Epoch 10/10\n",
            "782/782 - 256s - loss: 0.2385 - accuracy: 0.9201 - 256s/epoch - 327ms/step\n",
            "157/157 - 12s - loss: 0.8896 - accuracy: 0.7345 - 12s/epoch - 79ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8895913362503052, 0.734499990940094]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with the above functional model, we have introduced the batch normalization and with this we see training accuracy is increased to around 92% but the validation accuracy is around 72%. \n",
        "# Here we still see there is gap between training & validation accuracies & see we have overfit in the training & needs to be removed may be by introducind regularization.\n",
        "# So lets reuse the above functional_model method to introduce the couple of regularization techniques in our model & create a new method for that below.\n",
        "# we will introduce L2 regularization alogn with dropout in this case."
      ],
      "metadata": {
        "id": "LY-PXSCPENMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "ny2OuWrywKrT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# introducing L2 & Dropout regularizations\n",
        "\n",
        "def functional_model_regularization():\n",
        "  inputs = keras.Input(shape=(32, 32, 3))\n",
        "  x = layers.Conv2D(32, 3, padding='same', kernel_regularizer=regularizers.l2(0.01))(inputs)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = layers.MaxPool2D()(x)\n",
        "  x = layers.Conv2D(64, 5, padding='same', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = layers.Conv2D(128, 3, padding='same', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  outputs = layers.Dense(10)(x)\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  return model"
      ],
      "metadata": {
        "id": "pJZKBU2ef0hS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = functional_model_regularization()\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=3e-4),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "id": "w0Bx4NHImH5D",
        "outputId": "7979f946-f3b0-488d-eb19-2449e3a13e8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 - 337s - loss: 3.1139 - accuracy: 0.1094 - 337s/epoch - 431ms/step\n",
            "Epoch 2/10\n"
          ]
        }
      ]
    }
  ]
}